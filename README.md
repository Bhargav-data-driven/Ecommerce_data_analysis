# Ecommerce_data_analysis
 This project is designed to efficiently handle large datasets stored in CSV format by leveraging Pandas for data processing and PostgreSQL for database storage. The pipeline reads raw CSV data, creates a structured database table, and inserts the data using SQLAlchemy.

## Key Features
-  Load and process large CSV datasets using Pandas
-  Establish a connection with PostgreSQL using SQLAlchemy
-  Create and manage database tables dynamically
-  Append data efficiently to PostgreSQL
-  se Jupyter Notebook for data exploration and transformation

##  Workflow
**1.** Read the dataset from CSV files

**2.** Create a connection with PostgreSQL

**3.** Define and create database tables

**4.** Insert data into the database

**5.** Perform data analysis in Jupyter Notebook

 

## Use Case
This project is useful for data engineers, analysts, and developers who need to store and analyze large datasets in a structured database instead of handling them in raw CSV format. It is ideal for:

- Data warehousing

- ETL (Extract, Transform, Load) processes

- Business intelligence applications

## The dataset used in this project can be found [here](https://www.kaggle.com/datasets/psparks/instacart-market-basket-analysis/data)
